{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for practical part of PDC Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard limits to respect :\n",
    "- Codewords have to be in the space [-3/2, 3/2] x [-3/2, 3/2] -> **limits the energy per symbol**\n",
    "- The average energy of the vector **X** should be <= 1 -> **also limits the energy per symbol** \n",
    "- The dimension of the encoded vector **X** should not exceed n <= 100 -> **limits the number of symbols we can send**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IS THE ENERGY PER SYMBOL A HYPER-PARAMETER ???\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions to help code the encoder/decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the value of the Q-Function\n",
    "def q_function(x):\n",
    "    return (1/2) * sp.erfc(x/np.sqrt(2))\n",
    "\n",
    "# Gets every possible codeword lengths for which the length divides the total length of the original bitstring\n",
    "def compute_codeword_lengths(bit_str):\n",
    "    n = len(bit_str)\n",
    "    return [i for i in range(1, n+1) if n % i == 0]\n",
    "\n",
    "# Gets the whole alphabet from a codeword length\n",
    "def get_alphabet_from_codeword_length(length):\n",
    "    return [f'{i:0{length}b}' for i in range(0, 2**length)]\n",
    "\n",
    "# Performs a conversion from ASCII string to binary symbols\n",
    "def ascii_str_to_binary(ascii_str):\n",
    "    return str(''.join(format(ord(i), '08b') for i in ascii_str))\n",
    "\n",
    "def split_bit_str(bit_str, chunk_size):\n",
    "    return [bit_str[i:i+chunk_size] for i in range(0, len(bit_str), chunk_size)]\n",
    "\n",
    "\n",
    "# # Gets the encoded alphabet\n",
    "# def encode_alphabet(energy_per_symbol, alphabet, encoder):\n",
    "#     return [encoder(energy_per_symbol, i, alphabet) for i in alphabet]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for the types of encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m-PSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the probability of error for symbol i with PSK encoding (P_e(i) == P_e here !)\n",
    "def error_m_psk(i, m, energy_per_symbol, noise_var = 10**(-2.65)):\n",
    "    inner_part = lambda theta: np.exp(-(np.sin(np.pi/m)**2)**2 / np.sin(theta) * (energy_per_symbol/(2*(noise_var**2))))\n",
    "    return (1/np.pi) * sp.quad(inner_part, 0, np.pi - (np.pi / m))\n",
    "\n",
    "# Performs the m-PSK encoding\n",
    "def m_psk_encoder(energy_per_symbol, codeword, constellation, alphabet, d=0):\n",
    "    k = alphabet.index(codeword)\n",
    "    m = len(alphabet)\n",
    "    return np.sqrt(energy_per_symbol) * np.exp(2j * np.pi * (k/m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the probability of error for symbol i with QAM encoding (P_e(i) == P_e here !)\n",
    "def error_qam(m, d, noise_var = 10**(-2.65)):\n",
    "    func = q_function(d/(2*noise_var))\n",
    "    return 2*func - func**2\n",
    "\n",
    "# Computes the PAM constellation for a given number of points and a distance for each of these points.\n",
    "def pam(n, d):\n",
    "    right_side = np.array([d*i + (d/2) for i in range(0, int(n/2))])\n",
    "    left_side = -right_side\n",
    "    return np.append(np.sort(left_side), right_side)\n",
    "\n",
    "\n",
    "# Computes the whole m-QAM constellation, to be used to map each codeword to a point generated here\n",
    "# WARNING: m MUST BE A POWER OF 2 HERE !!!\n",
    "def m_qam(m, d, max_energy = (3/2)):\n",
    "    if d > max_energy:\n",
    "        raise OverflowError(\"ERROR: the distance you have set is too big for the project.\")\n",
    "\n",
    "    axis_len = int(np.sqrt(m))\n",
    "    if axis_len % 2 != 0:\n",
    "        axis_len = axis_len + 1\n",
    "\n",
    "    diff_with_nearest_square = m - axis_len**2\n",
    "\n",
    "    # if the difference is positive => we need to add some more points\n",
    "    if diff_with_nearest_square > 0:\n",
    "        real_axis_pam = pam(diff_with_nearest_square, d)\n",
    "    else:\n",
    "        real_axis_pam = pam(axis_len, d)\n",
    "    if real_axis_pam.max() > max_energy:\n",
    "        raise OverflowError(\"ERROR: You have some points that are outside the constrained square. Try to lower the distance or reduce the size of the constellation.\")\n",
    "    \n",
    "    imaginary_axis_pam = pam(axis_len, d)[::-1]\n",
    "    points_pairs = np.array([[complex(re, im) for re in real_axis_pam] for im in imaginary_axis_pam])\n",
    "\n",
    "    # if the difference is negative => we need to remove some points from the constellation\n",
    "    if diff_with_nearest_square < 0:\n",
    "        nb_elts_to_delete_per_half_row = np.sqrt(-diff_with_nearest_square)/2\n",
    "        nb_rows_to_modify = -diff_with_nearest_square / (2*nb_elts_to_delete_per_half_row)\n",
    "\n",
    "        # First we set them to 0\n",
    "        for j in range(0, int(nb_rows_to_modify/2)):\n",
    "            for i in range(0, int(nb_elts_to_delete_per_half_row)):\n",
    "                points_pairs[j, i] = 0\n",
    "                points_pairs[j, len(points_pairs)-1-i] = 0\n",
    "                points_pairs[len(points_pairs)-1-j, i] = 0\n",
    "                points_pairs[len(points_pairs)-1-j, len(points_pairs)-1-i] = 0\n",
    "\n",
    "    # We flatten the array to make it easier to map the codewords\n",
    "    points_pairs = points_pairs.flatten()\n",
    "\n",
    "    # Then, we remove all the points set to 0 (impossible to have if the dimension is a full square, so no worries)\n",
    "    points_pairs = np.delete(points_pairs, np.argwhere(points_pairs == 0.0+0.0j))\n",
    "\n",
    "    return points_pairs\n",
    "\n",
    "\n",
    "# Performs the QAM encoding (in a linear fashion for the moment => might be re-worked)\n",
    "def m_qam_encoder(codeword, constellation, alphabet, d, energy_per_symbol=0):\n",
    "    try:\n",
    "        k = alphabet.index(codeword)\n",
    "        m = len(alphabet)\n",
    "        return constellation[k]\n",
    "    except OverflowError as ovferr:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(raw_str, codeword_size, theta_estimator_batch_size, encoder, d = 1, energy_per_symbol = 1):\n",
    "    if theta_estimator_batch_size >= 100:\n",
    "        raise OverflowError(\"ERROR: The batch of dummy samples cannot be equal or exceed 100 symbols.\") \n",
    "    bit_str = ascii_str_to_binary(raw_str)\n",
    "    splitted_bit_str = split_bit_str(bit_str, codeword_size)\n",
    "    splitted_bit_str_size = len(splitted_bit_str)\n",
    "    if splitted_bit_str_size > 100:\n",
    "        raise OverflowError(\"ERROR: The string without the dummy symbols cannot exceed 100 symbols.\") \n",
    "\n",
    "    if splitted_bit_str_size + theta_estimator_batch_size > 100:\n",
    "        theta_estimator_batch_size = 100 - splitted_bit_str_size\n",
    "\n",
    "    alphabet = get_alphabet_from_codeword_length(codeword_size)\n",
    "    theta_estimator_batch = np.full((theta_estimator_batch_size, 1), alphabet[0])\n",
    "    full_str = np.append(theta_estimator_batch, splitted_bit_str)\n",
    "\n",
    "    if encoder == m_qam_encoder:\n",
    "        constellation = m_qam(2**codeword_size, d)\n",
    "    else: # FOR PSK COMPUTING THE CONSTELLATION IS USELESS\n",
    "        constellation = []\n",
    "\n",
    "    return np.array([encoder(energy_per_symbol=energy_per_symbol, codeword=codeword, constellation=constellation, alphabet=alphabet, d=d) for codeword in full_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel part (given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel(sent_signal):\n",
    "    s = np.mean(sent_signal**2)\n",
    "    if s <= 1:\n",
    "        s = 1\n",
    "    noise_power = (10**(-2.65))*s\n",
    "    shift = np.exp(-2j*np.pi*np.random.rand())\n",
    "    sent_signal = sent_signal*shift\n",
    "    noise_std = np.sqrt(noise_power/2)\n",
    "    rcv_signal = sent_signal + noise_std*np.random.randn(len(sent_signal)) + 1j*noise_std*np.random.randn(len(sent_signal))\n",
    "    return rcv_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_str(noisy_str, decoder, n_dummy_symbols):\n",
    "    dummy_symbols = noisy_str[0:n_dummy_symbols]\n",
    "    phase = np.mean(dummy_symbols) # TODO: CHECK HOW TO ISOLATE THE ANGLE FROM THE EXPONENTIAL IN THE EQUATION WITH THE MEAN\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible codeword sizes for the string hellohowareyoutodayimtryingtodecodethestringliketheonegivenattheexambutitshard of length 78:  [1, 2, 3, 4, 6, 8, 12, 13, 16, 24, 26, 39, 48, 52, 78, 104, 156, 208, 312, 624]\n",
      "[-0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j\n",
      " -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j\n",
      " -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j -0.75+0.75j\n",
      " -0.75+0.75j -0.75+0.75j  0.05+0.15j -0.25+0.15j  0.45+0.15j  0.45+0.15j\n",
      "  0.75+0.15j  0.05+0.15j  0.75+0.15j -0.05+0.05j -0.65+0.15j -0.55+0.05j\n",
      " -0.25+0.15j  0.15+0.05j  0.75+0.15j -0.25+0.05j -0.35+0.05j  0.75+0.15j\n",
      " -0.35+0.15j -0.65+0.15j  0.15+0.05j  0.15+0.15j  0.55+0.15j -0.35+0.05j\n",
      " -0.55+0.05j  0.15+0.05j  0.15+0.15j  0.65+0.15j -0.05+0.15j -0.35+0.05j\n",
      "  0.75+0.15j -0.35+0.15j -0.25+0.15j -0.45+0.15j  0.75+0.15j -0.35+0.15j\n",
      " -0.25+0.15j -0.35+0.05j  0.05+0.15j -0.25+0.15j -0.45+0.05j -0.35+0.05j\n",
      " -0.55+0.05j  0.15+0.15j  0.65+0.15j -0.05+0.15j  0.45+0.15j  0.15+0.15j\n",
      "  0.35+0.15j -0.25+0.15j -0.35+0.05j  0.05+0.15j -0.25+0.15j  0.75+0.15j\n",
      "  0.65+0.15j -0.25+0.15j -0.05+0.15j  0.15+0.15j -0.15+0.05j -0.25+0.15j\n",
      "  0.65+0.15j -0.65+0.15j -0.35+0.05j -0.35+0.05j  0.05+0.15j -0.25+0.15j\n",
      " -0.25+0.15j  0.05+0.05j -0.65+0.15j  0.55+0.15j -0.55+0.15j -0.25+0.05j\n",
      " -0.35+0.05j  0.15+0.15j -0.35+0.05j -0.45+0.05j  0.05+0.15j -0.65+0.15j\n",
      " -0.55+0.05j -0.35+0.15j]\n",
      "\n",
      "[-0.75323482-0.71980188j -0.79561855-0.73808675j -0.79289465-0.72836878j\n",
      " -0.75936589-0.74715294j -0.75021657-0.68780093j -0.81525543-0.74837791j\n",
      " -0.75854277-0.72501737j -0.83980754-0.71865359j -0.78189111-0.75568984j\n",
      " -0.77520095-0.69419401j -0.84305012-0.71358007j -0.75559196-0.76333534j\n",
      " -0.7850719 -0.71557149j -0.73380226-0.69544483j -0.77254699-0.722068j\n",
      " -0.80029691-0.74136755j -0.81188585-0.75155491j -0.78617727-0.76298616j\n",
      " -0.82835197-0.68215335j -0.81212785-0.76386716j -0.114342  +0.01605748j\n",
      " -0.15654168-0.24528098j -0.1431405 +0.45722839j -0.19336744+0.43388171j\n",
      " -0.13888919+0.73711035j -0.15017497+0.07538333j -0.09001232+0.75476368j\n",
      " -0.07293386-0.01092031j -0.17494671-0.63760447j -0.09123133-0.58651509j\n",
      " -0.18599847-0.26569856j -0.06948247+0.08811978j -0.12127499+0.73907298j\n",
      " -0.05330036-0.30113796j -0.12775456-0.40470357j -0.07722499+0.79364708j\n",
      " -0.15727219-0.30731821j -0.15392917-0.63285877j -0.04520121+0.14792188j\n",
      " -0.14368367+0.16146016j -0.12690941+0.56427576j -0.02267926-0.32862448j\n",
      " -0.0740396 -0.55701259j -0.0601597 +0.12018174j -0.12681723+0.17848067j\n",
      " -0.09945534+0.64352464j -0.16219442-0.02663125j -0.01314432-0.32576785j\n",
      " -0.10546409+0.79422139j -0.1562845 -0.36222676j -0.14043354-0.22490118j\n",
      " -0.15823381-0.41642191j -0.08681964+0.79139053j -0.14608115-0.29752035j\n",
      " -0.14261809-0.31368568j -0.04825312-0.34783011j -0.17024339+0.08975708j\n",
      " -0.18409653-0.29374786j -0.11256568-0.41866695j -0.07217269-0.27912865j\n",
      " -0.09360825-0.5410628j  -0.15287216+0.20457173j -0.17479038+0.65229668j\n",
      " -0.13977985-0.05828287j -0.14449132+0.44885304j -0.10446879+0.13877872j\n",
      " -0.17447783+0.39132507j -0.11123984-0.21709335j -0.117267  -0.41223925j\n",
      " -0.17972176+0.08500354j -0.11552443-0.30091311j -0.13124124+0.72578753j\n",
      " -0.12250886+0.66055369j -0.19432001-0.21163063j -0.20551064-0.02396631j\n",
      " -0.16735516+0.13050777j -0.04146781-0.13190931j -0.16823266-0.23916646j\n",
      " -0.08238938+0.66777711j -0.21094866-0.64623162j -0.07291875-0.33597712j\n",
      " -0.02546928-0.37527412j -0.15646434+0.07691691j -0.08453322-0.26767552j\n",
      " -0.15642084-0.27113648j -0.05747541+0.01233056j -0.2107765 -0.64933207j\n",
      " -0.09068941+0.50047788j -0.13186883-0.5048279j  -0.15948957-0.26024504j\n",
      " -0.03834593-0.34559554j -0.11462656+0.21251619j -0.06157854-0.33374119j\n",
      " -0.0710319 -0.42119628j -0.08488229+0.08634146j -0.17005291-0.62905047j\n",
      " -0.05698508-0.57676805j -0.21230977-0.35157816j]\n"
     ]
    }
   ],
   "source": [
    "str_to_process = \"hellohowareyoutodayimtryingtodecodethestringliketheonegivenattheexambutitshard\"\n",
    "\n",
    "print(f\"Possible codeword sizes for the string {str_to_process} of length {len(str_to_process)}: \", compute_codeword_lengths(ascii_str_to_binary(str_to_process)))\n",
    "\n",
    "try:\n",
    "    encoded_str = encode_string(str_to_process, codeword_size = 8, energy_per_symbol = 1, theta_estimator_batch_size = 20, d = 0.1, encoder = m_qam_encoder)\n",
    "except OverflowError as ovferr :\n",
    "    print(ovferr)\n",
    "    raise\n",
    "else:\n",
    "    print(encoded_str)\n",
    "    print()\n",
    "    noisy_result = channel(encoded_str)\n",
    "    print(noisy_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
