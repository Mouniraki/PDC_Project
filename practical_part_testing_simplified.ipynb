{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical part for the PDC project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions handling bit vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs a conversion from ASCII string to binary symbols\n",
    "def ascii_str_to_binary(ascii_str):\n",
    "    return str(''.join(format(ord(i), '08b')[1:] for i in ascii_str))\n",
    "\n",
    "# Performs the inverse conversion, from a binary stream to ASCII characters\n",
    "def binary_to_ascii_str(binstr):\n",
    "    byte_binstr = \"\".join([f\"0{byte}\" for byte in split_bit_str(binstr, 7)])\n",
    "    binary_int = int(byte_binstr, 2)\n",
    "    byte_number = binary_int.bit_length() + 7 // 8\n",
    "    binary_array = binary_int.to_bytes(byte_number, \"big\")\n",
    "    return binary_array.decode()\n",
    "\n",
    "# Splits a bit string composed of 7-bit codewords into chunks of size 'chunk_size'.\n",
    "def split_bit_str(bit_str, chunk_size):\n",
    "    return [bit_str[i:i+chunk_size] for i in range(0, len(bit_str), chunk_size)]\n",
    "\n",
    "# Gets the whole alphabet from a codeword length\n",
    "def get_alphabet_from_codeword_length(length):\n",
    "    return [f'{i:0{length}b}' for i in range(0, 2**length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding criterion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the distance between a symbol and every point of a given constellation and returns the index of the nearest point in the constellation\n",
    "def minimum_distance_criterion(constellation, symbol):\n",
    "    return np.argmin([((symbol.real - point.real)**2 + (symbol.imag - point.imag)**2) for point in constellation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging functions to check the encoding/decoding states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets every possible codeword lengths for which the length divides the total length of the original bitstring\n",
    "def compute_codeword_lengths(bit_str):\n",
    "    n = len(bit_str)\n",
    "    return [i for i in range(1, n+1) if n % i == 0]\n",
    "\n",
    "# Gets all the positions where bit_str1 is different from bit_str2 (bit_str1 and bit_str2 MUST HAVE THE SAME SIZE !)\n",
    "def get_diff_positions(bit_str1, bit_str2):\n",
    "    return [i for i in range(0, len(bit_str1)) if bit_str1[i] != bit_str2[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constellation-related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m-PSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the m-PSK encoding\n",
    "def m_psk_encoder(energy_per_symbol, codeword, alphabet, constellation = [], d=0):\n",
    "    k = alphabet.index(codeword)\n",
    "    m = len(alphabet)\n",
    "    return np.sqrt(energy_per_symbol) * np.exp(2j * np.pi * (k/m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m-QAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the PAM constellation for a given number of points and a distance for each of these points.\n",
    "def pam(n, d):\n",
    "    right_side = np.array([d*i + (d/2) for i in range(0, int(n/2))])\n",
    "    left_side = -right_side\n",
    "    return np.append(np.sort(left_side), right_side)\n",
    "\n",
    "# Computes the whole m-QAM constellation, to be used to map each codeword to a point generated here\n",
    "# WARNING: m MUST BE A POWER OF 2 HERE !!!\n",
    "def m_qam(m, d, max_energy = (3/2)):\n",
    "    if d > max_energy:\n",
    "        raise OverflowError(\"ERROR: the distance you have set is too big for the project.\")\n",
    "\n",
    "    axis_len = int(np.sqrt(m))\n",
    "    if axis_len % 2 != 0:\n",
    "        axis_len = axis_len + 1\n",
    "\n",
    "    diff_with_nearest_square = m - axis_len**2\n",
    "\n",
    "    # if the difference is positive => we need to add some more points\n",
    "    if diff_with_nearest_square > 0:\n",
    "        real_axis_pam = pam(diff_with_nearest_square, d)\n",
    "    else:\n",
    "        real_axis_pam = pam(axis_len, d)\n",
    "    if real_axis_pam.max() > max_energy:\n",
    "        raise OverflowError(\"ERROR: You have some points that are outside the constrained square. Try to lower the distance or reduce the size of the constellation.\")\n",
    "    \n",
    "    imaginary_axis_pam = pam(axis_len, d)[::-1]\n",
    "    points_pairs = np.array([[complex(re, im) for re in real_axis_pam] for im in imaginary_axis_pam])\n",
    "\n",
    "    # if the difference is negative => we need to remove some points from the constellation\n",
    "    if diff_with_nearest_square < 0:\n",
    "        nb_elts_to_delete_per_half_row = np.sqrt(-diff_with_nearest_square)/2\n",
    "        nb_rows_to_modify = -diff_with_nearest_square / (2*nb_elts_to_delete_per_half_row)\n",
    "\n",
    "        # First we set them to 0\n",
    "        for j in range(0, int(nb_rows_to_modify/2)):\n",
    "            for i in range(0, int(nb_elts_to_delete_per_half_row)):\n",
    "                points_pairs[j, i] = 0\n",
    "                points_pairs[j, len(points_pairs)-1-i] = 0\n",
    "                points_pairs[len(points_pairs)-1-j, i] = 0\n",
    "                points_pairs[len(points_pairs)-1-j, len(points_pairs)-1-i] = 0\n",
    "\n",
    "    # We flatten the array to make it easier to map the codewords\n",
    "    points_pairs = points_pairs.flatten()\n",
    "\n",
    "    # Then, we remove all the points set to 0 (impossible to have if the dimension is a full square, so no worries)\n",
    "    points_pairs = np.delete(points_pairs, np.argwhere(points_pairs == 0.0+0.0j))\n",
    "\n",
    "    return points_pairs\n",
    "\n",
    "\n",
    "# Performs the QAM encoding (in a linear fashion for the moment => might be re-worked)\n",
    "def m_qam_encoder(codeword, constellation, alphabet, energy_per_symbol=0):\n",
    "    try:\n",
    "        k = alphabet.index(codeword)\n",
    "        m = len(alphabet)\n",
    "        return constellation[k]\n",
    "    except OverflowError as ovferr:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes a string into a sequence of complex numbers & adds dummy points in front of it, given an encoder, a constellation, an alphabet and a number of dummy points\n",
    "def encode_string(raw_str, n_dummy_symbols, encoder, dummy_symbol, constellation = [], alphabet = []):\n",
    "    if n_dummy_symbols >= 100:\n",
    "        raise OverflowError(\"ERROR: The batch of dummy samples cannot be equal or exceed 100 symbols.\") \n",
    "    bit_str = ascii_str_to_binary(raw_str)\n",
    "    splitted_bit_str = split_bit_str(bit_str, int(np.log2(len(alphabet))))\n",
    "    splitted_bit_str_size = len(splitted_bit_str)\n",
    "    if splitted_bit_str_size > 100:\n",
    "        raise OverflowError(\"ERROR: The string without the dummy symbols cannot exceed 100 symbols.\") \n",
    "\n",
    "    if splitted_bit_str_size + n_dummy_symbols > 100:\n",
    "        raise OverflowError(f\"ERROR: the number of dummy samples is too high, the max value you can set here is {100 - splitted_bit_str_size}.\")\n",
    "            \n",
    "    theta_estimator_batch = np.full((n_dummy_symbols, 1), dummy_symbol)\n",
    "\n",
    "    return np.append(theta_estimator_batch, np.array([encoder(codeword=codeword, constellation=constellation, alphabet=alphabet) for codeword in splitted_bit_str]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel part (given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel(sent_signal):\n",
    "    s = np.mean(sent_signal**2)\n",
    "    if s <= 1:\n",
    "        s = 1\n",
    "    noise_power = (10**(-2.65))*s\n",
    "    shift = np.exp(-2j*np.pi*np.random.rand())\n",
    "    # print(f\"Applied shift: {np.angle(shift)}\")\n",
    "    sent_signal = sent_signal*shift\n",
    "    noise_std = np.sqrt(noise_power/2)\n",
    "    rcv_signal = sent_signal + noise_std*np.random.randn(len(sent_signal)) + 1j*noise_std*np.random.randn(len(sent_signal))\n",
    "    return rcv_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes a bitstring outputted by the channel, given a constellation, an alphabet, a dummy symbol and the number of sent dummy symbols.\n",
    "\n",
    "def decode_str(noisy_str, dummy_symbol, n_dummy_symbols, alphabet, constellation):\n",
    "    # Isolate the dummy symbols to estimate the phase shift\n",
    "    dummy_symbols = noisy_str[0:n_dummy_symbols]\n",
    "    \n",
    "    # Estimate the phase shift (np.angle gives a value between (-pi, pi])\n",
    "    phase = (np.angle(np.sum(dummy_symbols)) + np.pi) - (np.angle(dummy_symbol) + np.pi) \n",
    "\n",
    "    # print(f\"Estimated phase: {phase}, phase with normalization: {phase % 2*np.pi}\")\n",
    "    # Apply the inverse phase shift to every codeword\n",
    "    dephased_symbols = np.exp(-1j * phase) * noisy_str[n_dummy_symbols:]\n",
    "\n",
    "    decoded_codewords = [alphabet[minimum_distance_criterion(constellation, symbol)] for symbol in dephased_symbols]\n",
    "    resulting_bit_str = \"\".join(decoded_codewords)\n",
    "    return resulting_bit_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78-chars ASCII string -> TO BE CHANGED FOR EACH \n",
    "str_to_process = \"hellohowareyoutodayimtryingtodecodethestringliketheonegivenattheexambutitshard\"\n",
    "\n",
    "max_energy = 3/2\n",
    "encoder = m_qam_encoder\n",
    "dummy_symbol = max_energy + 1j * max_energy\n",
    "original_bitstr = ascii_str_to_binary(str_to_process)\n",
    "\n",
    "# TODO: VARY BOTH DISTANCE_RANGE & N_DUMMY_SYMBOLS TO FIND BEST PARAMETERS (i.e., those for which the decoding is perfect)\n",
    "distance_range = np.arange(0.15, max_energy, 0.01) # (start_value, max_value, step_increment_value)\n",
    "n_dummy_symbols = 9\n",
    "\n",
    "best_distance_values_per_qam_configuration = dict()\n",
    "\n",
    "print(f\"Performing an encoding/decoding on the string {str_to_process}:\")\n",
    "for codeword_size in compute_codeword_lengths(ascii_str_to_binary(str_to_process)):\n",
    "    # We limit the size of codewords to avoid unrealistic constellations given our max-energy constraint\n",
    "    if 2 <= codeword_size and codeword_size <= 10:\n",
    "        ideal_distances = []\n",
    "        for d in distance_range:\n",
    "            try:\n",
    "                constellation = m_qam(2**codeword_size, d)\n",
    "                alphabet = get_alphabet_from_codeword_length(codeword_size)\n",
    "\n",
    "                # We encode the string\n",
    "                encoded_str = encode_string(str_to_process, constellation=constellation, alphabet=alphabet, n_dummy_symbols=n_dummy_symbols, dummy_symbol=dummy_symbol, encoder=encoder)\n",
    "\n",
    "                # We pass it to the channel\n",
    "                noisy_result = channel(encoded_str)\n",
    "\n",
    "                # We decode it finally\n",
    "                decoded_bitstr = decode_str(noisy_result, dummy_symbol=dummy_symbol, n_dummy_symbols=n_dummy_symbols, alphabet=alphabet, constellation=constellation)\n",
    "                diff_positions = get_diff_positions(original_bitstr, decoded_bitstr)\n",
    "\n",
    "                if len(diff_positions) == 0:\n",
    "                    ideal_distances.append(d)      \n",
    "            except OverflowError as ovferr:\n",
    "                break #Â Go to another QAM configuration when we reach/go past the max-energy limit\n",
    "            except UnicodeDecodeError as unicodeerr:\n",
    "                continue\n",
    "\n",
    "        best_distance_values_per_qam_configuration[f\"{2**codeword_size}-QAM\"] = ideal_distances\n",
    "\n",
    "# For each valid QAM configuration : print the best distance values\n",
    "for key, value in best_distance_values_per_qam_configuration.items():\n",
    "    print(key)\n",
    "    print(f\" -> {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
