{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical part for the PDC project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions handling bit vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a 78-character ASCII string at random.\n",
    "def generate_ascii_strings():\n",
    "    return \"\".join([chr(int(np.random.rand()*127)) for i in range(0, 78)])\n",
    "\n",
    "# Performs a conversion from ASCII string to binary symbols\n",
    "def ascii_str_to_binary(ascii_str):\n",
    "    return str(''.join(format(ord(i), '08b')[1:] for i in ascii_str))\n",
    "\n",
    "# Performs the inverse conversion, from a binary stream to ASCII characters\n",
    "def binary_to_ascii_str(binstr):\n",
    "    byte_binstr = \"\".join([f\"0{byte}\" for byte in split_bit_str(binstr, 7)])\n",
    "    binary_int = int(byte_binstr, 2)\n",
    "    byte_number = binary_int.bit_length() + 7 // 8\n",
    "    binary_array = binary_int.to_bytes(byte_number, \"big\")\n",
    "    return binary_array.decode()\n",
    "\n",
    "# Splits a bit string composed of 7-bit codewords into chunks of size 'chunk_size'.\n",
    "def split_bit_str(bit_str, chunk_size):\n",
    "    return [bit_str[i:i+chunk_size] for i in range(0, len(bit_str), chunk_size)]\n",
    "\n",
    "# Gets the whole alphabet from a codeword length\n",
    "def get_alphabet_from_codeword_length(length):\n",
    "    return [f'{i:0{length}b}' for i in range(0, 2**length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding criterion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the distance between a symbol and every point of a given constellation and returns the index of the nearest point in the constellation\n",
    "def minimum_distance_criterion(constellation, symbol):\n",
    "    return np.argmin([((symbol.real - point.real)**2 + (symbol.imag - point.imag)**2) for point in constellation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging functions to check the encoding/decoding states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets every possible codeword lengths for which the length divides the total length of the original bitstring\n",
    "def compute_codeword_lengths(bit_str):\n",
    "    n = len(bit_str)\n",
    "    return [i for i in range(1, n+1) if n % i == 0]\n",
    "\n",
    "# Gets all the positions where bit_str1 is different from bit_str2 (bit_str1 and bit_str2 MUST HAVE THE SAME SIZE !)\n",
    "def get_diff_positions(bit_str1, bit_str2):\n",
    "    return [i for i in range(0, len(bit_str1)) if bit_str1[i] != bit_str2[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constellation-related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m-QAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the PAM constellation for a given number of points and a distance for each of these points.\n",
    "def pam(n, d):\n",
    "    right_side = np.array([d*i + (d/2) for i in range(0, int(n/2))])\n",
    "    left_side = -right_side\n",
    "    return np.append(np.sort(left_side), right_side)\n",
    "\n",
    "# Computes the whole m-QAM constellation, to be used to map each codeword to a point generated here\n",
    "# WARNING: m MUST BE A POWER OF 2 HERE !!!\n",
    "def m_qam(m, d, max_energy = (3/2)):\n",
    "    if d > max_energy:\n",
    "        raise OverflowError(\"ERROR: the distance you have set is too big for the project.\")\n",
    "\n",
    "    # First we handle the weird configurations\n",
    "    if m == 2:\n",
    "        return pam(m, d)\n",
    "\n",
    "    elif m == 8:\n",
    "        real_axis_pam = pam(4, d)\n",
    "        imaginary_axis_pam = pam(2, d)\n",
    "        return np.array([[complex(re, im) for re in real_axis_pam] for im in imaginary_axis_pam]).flatten()\n",
    "\n",
    "    else:    \n",
    "        # First we take the square root of the QAM size, if it is an integer then we will generate a perfect square\n",
    "        # Otherwise, we try to find the nearest perfect square with sides of even lengths such that it contains more points than our desired constellation\n",
    "        axis_len = int(np.sqrt(m))\n",
    "\n",
    "        if axis_len**2 != m:\n",
    "             # We want axes containing an even number of points, and a bigger constellation than the one we requested in this case\n",
    "            if axis_len % 2 != 0:\n",
    "                axis_len += 1\n",
    "            else:\n",
    "                axis_len += 2\n",
    "\n",
    "        # We compute the difference between the number of points in the nearest perfect square and the number of points in our requested constellation\n",
    "        nb_points_to_delete = abs(m - axis_len**2)\n",
    "\n",
    "        # if the difference is positive => we need to remove 'diff_with_nearest_square' points from the nearest perfect square\n",
    "        # => we generate the perfect square before removing points inside it\n",
    "        real_axis_pam = pam(axis_len, d)\n",
    "        if real_axis_pam.max() > max_energy:\n",
    "            raise OverflowError(\"ERROR: You have some points that are outside the constrained square. Try to lower the distance or reduce the size of the constellation.\")\n",
    "        \n",
    "        imaginary_axis_pam = pam(axis_len, d)[::-1]\n",
    "        points_pairs = np.array([[complex(re, im) for re in real_axis_pam] for im in imaginary_axis_pam])\n",
    "\n",
    "        # Now that the constellation has been generated, if diff_with_nearest_square is not 0 we remove the additional points\n",
    "        if nb_points_to_delete > 0:\n",
    "            nb_points_to_remove_per_quarter = nb_points_to_delete / 4\n",
    "            nb_rows_to_affect_per_quarter = int(np.sqrt(nb_points_to_remove_per_quarter))\n",
    "\n",
    "            # If the square root isn't whole => we must re-organize the zones where to delete the points (they are not squares anymore)\n",
    "            difference_from_whole_square = nb_points_to_remove_per_quarter - nb_rows_to_affect_per_quarter**2\n",
    "\n",
    "            if difference_from_whole_square > 0:\n",
    "                nb_rows_to_affect_per_quarter = difference_from_whole_square\n",
    "                nb_points_to_remove_per_quarter_row = nb_points_to_remove_per_quarter / difference_from_whole_square\n",
    "            else:\n",
    "                nb_points_to_remove_per_quarter_row = nb_rows_to_affect_per_quarter\n",
    "\n",
    "            # First we set the points to delete to 0\n",
    "            for j in range(0, int(nb_rows_to_affect_per_quarter)):\n",
    "                for i in range(0, int(nb_points_to_remove_per_quarter_row)):\n",
    "                    points_pairs[j, i] = 0\n",
    "                    points_pairs[j, len(points_pairs[0])-1-i] = 0\n",
    "                    points_pairs[len(points_pairs[0])-1-j, i] = 0\n",
    "                    points_pairs[len(points_pairs[0])-1-j, len(points_pairs[0])-1-i] = 0\n",
    "\n",
    "        # We flatten the array to make it easier to map the codewords\n",
    "        points_pairs = points_pairs.flatten()\n",
    "\n",
    "        # Then, we remove all the points set to 0 (impossible to have if the dimension is a square with sides of even length, so no worries)\n",
    "        points_pairs = np.delete(points_pairs, np.argwhere(points_pairs == 0.0+0.0j))\n",
    "\n",
    "        return points_pairs\n",
    "\n",
    "# Gets the maximum distance for a given QAM configuration\n",
    "def get_max_qam_distance(m, tolerance, max_energy):\n",
    "    if m == 2:\n",
    "        pam_size = 2\n",
    "    elif m == 8:\n",
    "        pam_size = 4\n",
    "    else:\n",
    "        pam_size = int(np.sqrt(m))\n",
    "        if pam_size**2 != m:\n",
    "            # We want axes containing an even number of points, and a bigger constellation than the one we requested in this case\n",
    "            if pam_size % 2 != 0:\n",
    "                pam_size += 1\n",
    "            else:\n",
    "                pam_size += 2\n",
    "\n",
    "    max_distance = 0.0\n",
    "    for d in np.arange(0, max_energy, tolerance):\n",
    "        real_axis_pam = pam(pam_size, d)\n",
    "        if real_axis_pam.max() <= max_energy:\n",
    "            max_distance = d\n",
    "        else:\n",
    "            return max_distance\n",
    "    return max_distance\n",
    "    \n",
    "\n",
    "# Performs the QAM encoding (in a linear fashion for the moment => might be re-worked)\n",
    "def m_qam_encoder(codeword, constellation, alphabet, energy_per_symbol=0):\n",
    "    try:\n",
    "        k = alphabet.index(codeword)\n",
    "        m = len(alphabet)\n",
    "        return constellation[k]\n",
    "    except OverflowError as ovferr:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes a string into a sequence of complex numbers & adds dummy points in front of it, given an encoder, a constellation, an alphabet and a number of dummy points\n",
    "def encode_string(raw_str, n_dummy_symbols, encoder, dummy_symbol, constellation = [], alphabet = []):\n",
    "    if n_dummy_symbols >= 100:\n",
    "        raise OverflowError(\"ERROR: The batch of dummy samples cannot be equal or exceed 100 symbols.\") \n",
    "    bit_str = ascii_str_to_binary(raw_str)\n",
    "    splitted_bit_str = split_bit_str(bit_str, int(np.log2(len(alphabet))))\n",
    "    splitted_bit_str_size = len(splitted_bit_str)\n",
    "    if splitted_bit_str_size > 100:\n",
    "        raise OverflowError(\"ERROR: The string without the dummy symbols cannot exceed 100 symbols.\") \n",
    "\n",
    "    if splitted_bit_str_size + n_dummy_symbols > 100:\n",
    "        raise OverflowError(f\"ERROR: the number of dummy samples is too high, the max value you can set here is {100 - splitted_bit_str_size}.\")\n",
    "            \n",
    "    theta_estimator_batch = np.full((n_dummy_symbols, 1), dummy_symbol)\n",
    "\n",
    "    return np.append(theta_estimator_batch, np.array([encoder(codeword=codeword, constellation=constellation, alphabet=alphabet) for codeword in splitted_bit_str]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel part (given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel(sent_signal):\n",
    "    s = np.mean(np.absolute(sent_signal)**2)\n",
    "    if s <= 1:\n",
    "        s = 1\n",
    "    noise_power = (10**(-2.65))*s\n",
    "    shift = np.exp(-2j*np.pi*np.random.rand())\n",
    "    sent_signal = sent_signal*shift\n",
    "    noise_std = np.sqrt(noise_power/2)\n",
    "    rcv_signal = sent_signal + noise_std*np.random.randn(len(sent_signal)) + 1j*noise_std*np.random.randn(len(sent_signal))\n",
    "    return rcv_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes a bitstring outputted by the channel, given a constellation, an alphabet, a dummy symbol and the number of sent dummy symbols.\n",
    "\n",
    "def decode_str(noisy_str, dummy_symbol, n_dummy_symbols, alphabet, constellation):\n",
    "    # Isolate the dummy symbols to estimate the phase shift\n",
    "    dummy_symbols = noisy_str[0:n_dummy_symbols]\n",
    "    \n",
    "    # Estimate the phase shift (np.angle gives a value between (-pi, pi])\n",
    "    phase = (np.angle(np.sum(dummy_symbols)) + np.pi) - (np.angle(dummy_symbol) + np.pi) \n",
    "\n",
    "    # print(f\"Estimated phase: {phase}, phase with normalization: {phase % 2*np.pi}\")\n",
    "    # Apply the inverse phase shift to every codeword\n",
    "    dephased_symbols = np.exp(-1j * phase) * noisy_str[n_dummy_symbols:]\n",
    "\n",
    "    decoded_codewords = [alphabet[minimum_distance_criterion(constellation, symbol)] for symbol in dephased_symbols]\n",
    "    resulting_bit_str = \"\".join(decoded_codewords)\n",
    "    return resulting_bit_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of errors per QAM configuration, for for n_dummy_symbols ranging from 0 to 22:\n",
      "{'4': [], '8': [], '64': [47.289377289377285, 0.005494505494505495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003663003663003663, 0.0], '128': [48.71794871794872, 0.20146520146520144, 0.14285714285714282, 0.12454212454212453, 0.12820512820512817, 0.10073260073260071, 0.11355311355311352, 0.13553113553113547, 0.13186813186813182, 0.2014652014652014, 0.21428571428571422, 0.16483516483516486, 0.2197802197802197, 0.21062271062271054, 0.21978021978021964, 0.29304029304029294, 0.19047619047619038, 0.25091575091575086, 0.23992673992673985, 0.24908424908424898, 0.36263736263736246, 0.31868131868131844, 0.3919413919413917]}\n",
      "\n",
      "Probability of error for 4-QAM and each value of n_dummy_symbols -> []\n",
      "Probability of error for 8-QAM and each value of n_dummy_symbols -> []\n",
      "Probability of error for 64-QAM and each value of n_dummy_symbols -> [0.4728937728937728, 5.494505494505495e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.663003663003663e-05, 0.0]\n",
      "Probability of error for 128-QAM and each value of n_dummy_symbols -> [0.4871794871794872, 0.0020146520146520144, 0.0014285714285714281, 0.0012454212454212452, 0.0012820512820512816, 0.001007326007326007, 0.0011355311355311353, 0.0013553113553113547, 0.0013186813186813182, 0.002014652014652014, 0.002142857142857142, 0.0016483516483516486, 0.002197802197802197, 0.0021062271062271052, 0.0021978021978021965, 0.0029304029304029295, 0.001904761904761904, 0.0025091575091575084, 0.0023992673992673987, 0.00249084249084249, 0.0036263736263736244, 0.0031868131868131844, 0.0039194139194139175]\n"
     ]
    }
   ],
   "source": [
    "max_energy = 3/2\n",
    "encoder = m_qam_encoder\n",
    "dummy_symbol = max_energy + 1j * max_energy\n",
    "\n",
    "# TODO: PLAY WITH THE VALUES HERE\n",
    "nb_strings = 100\n",
    "distance_margin = 0.001\n",
    "\n",
    "set_of_random_strings = [generate_ascii_strings() for i in range(0, nb_strings)]\n",
    "range_of_dummy_symbols = range(0, 23) # LIMIT FOR 64-QAM IS 9 SYMBOLS, LIMIT FOR 128-QAM IS 22 SYMBOLS -> MAKES NO SENSE TO GO BEYOND 23\n",
    "\n",
    "histogram_per_qam = {}\n",
    "\n",
    "for str_to_process in set_of_random_strings:\n",
    "    original_bitstr = ascii_str_to_binary(str_to_process)\n",
    "\n",
    "    for codeword_size in compute_codeword_lengths(original_bitstr):\n",
    "        if 2 <= codeword_size and codeword_size <= 10:\n",
    "            histogram = []\n",
    "\n",
    "            qam_size = 2**codeword_size\n",
    "            d = get_max_qam_distance(qam_size, distance_margin, max_energy)\n",
    "            constellation = m_qam(qam_size, d)\n",
    "            alphabet = get_alphabet_from_codeword_length(codeword_size)\n",
    "\n",
    "            if len(constellation) > 0:\n",
    "                for n_dummy_symbols in range_of_dummy_symbols:\n",
    "                    try:\n",
    "                        # We encode the string\n",
    "                        encoded_str = encode_string(\n",
    "                            str_to_process, \n",
    "                            constellation=constellation, \n",
    "                            alphabet=alphabet, \n",
    "                            n_dummy_symbols=n_dummy_symbols, \n",
    "                            dummy_symbol=dummy_symbol, \n",
    "                            encoder=encoder\n",
    "                        )\n",
    "\n",
    "                        # We pass it through the channel\n",
    "                        noisy_str = channel(encoded_str)\n",
    "\n",
    "                        # We decode the string\n",
    "                        decoded_bitstr = decode_str(\n",
    "                            noisy_str, \n",
    "                            dummy_symbol=dummy_symbol, \n",
    "                            n_dummy_symbols=n_dummy_symbols, \n",
    "                            alphabet=alphabet,\n",
    "                            constellation=constellation\n",
    "                        )\n",
    "\n",
    "                        # We compute all the positions where there are errors in the decoding process\n",
    "                        diff_positions = get_diff_positions(original_bitstr, decoded_bitstr)\n",
    "                        # We divide the number of bit errors by the total length of the bitstring => better metric for the histogram\n",
    "                        histogram.append(len(diff_positions) / len(original_bitstr))\n",
    "\n",
    "                    except OverflowError as ovferr: #Â Go to another QAM configuration when we reach/go past the max-energy limit\n",
    "                        break\n",
    "                    except UnicodeDecodeError as unicodeerr:\n",
    "                        continue\n",
    "            \n",
    "            key = f\"{qam_size}\"\n",
    "            if key in histogram_per_qam:\n",
    "                histogram_per_qam[key] = [histogram_per_qam[key][i] + histogram[i] for i in range(0, len(histogram))]\n",
    "            else:\n",
    "                histogram_per_qam[key] = histogram\n",
    "\n",
    "print(f\"Histogram of errors per QAM configuration, for for n_dummy_symbols ranging from 0 to 22:\")\n",
    "print(histogram_per_qam)\n",
    "print()\n",
    "for key, value in histogram_per_qam.items():\n",
    "    print(f\"Probability of error for {key}-QAM and each value of n_dummy_symbols -> {[errors/nb_strings for errors in value]}\")\n",
    "\n",
    "# x = [ele.real for ele in data]\n",
    "# y = [ele.imag for ele in data]\n",
    "  \n",
    "# # Plot the constellation\n",
    "# plt.scatter(x, y)\n",
    "# plt.ylabel('Imaginary')\n",
    "# plt.xlabel('Real')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
